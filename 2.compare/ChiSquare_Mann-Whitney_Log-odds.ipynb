{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dbamman/anlp24/blob/main/2.compare/ChiSquare_Mann-Whitney_Log-odds.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook examines the words that distinguish the [2024 Democrat party platform](https://www.presidency.ucsb.edu/documents/2024-democratic-party-platform) from the [2024 Republican party platform](https://www.presidency.ucsb.edu/documents/2024-republican-party-platform) (both sourced from the American Presidency Project at UCSB), using the Chi-Square test, Mann-Whitney test and log-odds ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-check-certificate https://raw.githubusercontent.com/dbamman/anlp24/main/data/2024_democrat_party_platform.txt\n",
    "!wget --no-check-certificate https://raw.githubusercontent.com/dbamman/anlp24/main/data/2024_republican_party_platform.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import nltk\n",
    "import math\n",
    "import operator\n",
    "from collections import Counter\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(filename):\n",
    "    with open(filename, encoding=\"utf-8\") as file:\n",
    "        # lowercase text\n",
    "        return file.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "democratText=read(\"2024_democrat_party_platform.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "republicanText=read(\"2024_republican_party_platform.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore your assumptions between the words you think will most distinguish the Democrat and Republican platforms.  Before looking at the results of the tests, what words do you think will be comparatively distinct to both?  (If you're not familiar with either, scan the platforms linked above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    return nltk.word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(tokens):\n",
    "    counts=Counter()\n",
    "    for token in tokens:\n",
    "        counts[token]+=1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\chi^2$ test\n",
    "\n",
    "The $\\chi^2$ test as used in the comparison of different texts is designed to measure how statistically significant the distriubtion of counts in a 2x2 contingency table is.  Use the following function to analyze the difference between the platforms.  How do the most distinct terms comport with your assumptions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square(one_counts, two_counts):\n",
    "\n",
    "    one_sum=0.\n",
    "    two_sum=0.\n",
    "    vocab={}\n",
    "    for word in one_counts:\n",
    "        one_sum+=one_counts[word]\n",
    "        vocab[word]=1\n",
    "    for word in two_counts:\n",
    "        vocab[word]=1\n",
    "        two_sum+=two_counts[word]\n",
    "\n",
    "    N=one_sum+two_sum\n",
    "    vals={}\n",
    "    \n",
    "    for word in vocab:\n",
    "        O11=one_counts[word]\n",
    "        O12=two_counts[word]\n",
    "        O21=one_sum-one_counts[word]\n",
    "        O22=two_sum-two_counts[word]\n",
    "        \n",
    "        # We'll use the simpler form given in Manning and Schuetze (1999) \n",
    "        # for 2x2 contingency tables: \n",
    "        # https://nlp.stanford.edu/fsnlp/promo/colloc.pdf, equation 5.7\n",
    "        \n",
    "        vals[word]=(N*(O11*O22 - O12*O21)**2)/((O11 + O12)*(O11+O21)*(O12+O22)*(O21+O22))\n",
    "        \n",
    "    sorted_chi = sorted(vals.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    one=[]\n",
    "    two=[]\n",
    "    for k,v in sorted_chi:\n",
    "        if one_counts[k]/one_sum > two_counts[k]/two_sum:\n",
    "            one.append(k)\n",
    "        else:\n",
    "            two.append(k)\n",
    "    \n",
    "    print (\"Democrat:\\n\")\n",
    "    for k in one[:20]:\n",
    "        print(\"%s\\t%s\" % (k,vals[k]))\n",
    "\n",
    "    print (\"\\n\\nRepublican:\\n\")\n",
    "    for k in two[:20]:\n",
    "        print(\"%s\\t%s\" % (k,vals[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "democrat_tokens=tokenize(democratText)\n",
    "democrat_counts=get_counts(democrat_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "republican_tokens=tokenize(republicanText)\n",
    "republican_counts=get_counts(republican_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chi_square(democrat_counts, republican_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are these results surprising? Examine specific words to check their frequency in both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Totals: R: %s, D: %s\" % (len(republican_tokens), len(democrat_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word=\"climate\"\n",
    "print(\"%s -- R: %s, D: %s\" % (word, republican_counts[word], democrat_counts[word]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mann-Whitney\n",
    "\n",
    "We saw earlier that $\\chi^2$ is not a perfect estimator since doesn't account for the \"burstiness\" of language -- if we see the word \"Dracula\" in a text, we're probably going to see it again in that same text. The occurrence of words are not independent random events; they are tightly coupled with each other. If we're trying to understanding the robust differences between two corpora, we might prefer to prioritize words that show up more frequently everywhere in corpus A (but not in corpus B) over those that show up only very frequently within narrow slice of A (such as one text in a genre, one chapter in a book, or one speaker when measuring the differences between policital parties). Use the following function to execute the Mann-Whitney test to account for this phenomenon while finding distinctive terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_differences(one_tokens, two_tokens):\n",
    "    one_N=len(one_tokens)\n",
    "    two_N=len(two_tokens)\n",
    "    \n",
    "    one_counts=Counter()\n",
    "    two_counts=Counter()\n",
    "    \n",
    "    vocab={}\n",
    "    for token in one_tokens:\n",
    "        one_counts[token]+=1\n",
    "        vocab[token]=1\n",
    "        \n",
    "    for token in two_tokens:\n",
    "        two_counts[token]+=1    \n",
    "        vocab[token]=1\n",
    "        \n",
    "    differences={}\n",
    "    for word in vocab:\n",
    "        freq1=one_counts[word]/one_N\n",
    "        freq2=two_counts[word]/two_N\n",
    "        \n",
    "        diff=freq1-freq2\n",
    "        differences[word]=diff\n",
    "        \n",
    "    return differences\n",
    "\n",
    "# convert a sequence of tokens into counts for each chunkLength-word window\n",
    "def get_chunk_counts(tokens, chunkLength):\n",
    "    chunks=[]\n",
    "    for i in range(0, len(tokens), chunkLength):\n",
    "            counts=Counter()\n",
    "            for j in range(chunkLength):\n",
    "                if i+j < len(tokens):\n",
    "                    counts[tokens[i+j]]+=1\n",
    "            chunks.append(counts)\n",
    "    return chunks\n",
    "\n",
    "# calculate mann-whitney test for each word in vocabulary\n",
    "def mann_whitney(one_tokens, two_tokens):\n",
    "\n",
    "    chunkLength=500\n",
    "    one_chunks=get_chunk_counts(one_tokens, chunkLength)\n",
    "    two_chunks=get_chunk_counts(two_tokens, chunkLength)\n",
    "    \n",
    "    # vocab is the union of terms in both sets\n",
    "    vocab={}\n",
    "    \n",
    "    for chunk in one_chunks:\n",
    "        for word in chunk:\n",
    "            vocab[word]=1\n",
    "    for chunk in two_chunks:\n",
    "        for word in chunk:\n",
    "            vocab[word]=1\n",
    "    \n",
    "    pvals={}\n",
    "    \n",
    "    for word in vocab:\n",
    "        \n",
    "        a=[]\n",
    "        b=[]\n",
    "        \n",
    "        # Note a and b can be different lengths (i.e., different sample sizes)\n",
    "        # \n",
    "        # See Mann and Whitney (1947), \"On a Test of Whether one of Two Random \n",
    "        # Variables is Stochastically Larger than the Other\"\n",
    "        # https://projecteuclid.org/download/pdf_1/euclid.aoms/1177730491\n",
    "        \n",
    "        # (This is part of their innovation over the case of equal sample sizes in Wilcoxon 1945)\n",
    "        \n",
    "        for chunk in one_chunks:\n",
    "            a.append(chunk[word])\n",
    "        for chunk in two_chunks:\n",
    "            b.append(chunk[word])\n",
    "\n",
    "        statistic,pval=mannwhitneyu(a,b, alternative=\"two-sided\")\n",
    "        \n",
    "        # We'll use the p-value as our quantity of interest.  [Note in the normal appproximation\n",
    "        # that Mann-Whitney uses to assess significance for large sample sizes, the significance \n",
    "        # of the raw statistic depends on the number of ties in the data, so the statistic itself\n",
    "        # isn't exactly comparable across different words]\n",
    "        pvals[word]=pval\n",
    "\n",
    "    return pvals\n",
    "    \n",
    "# calculate mann-whitneyfor each word in vocabulary and present the top 10 terms for each group\n",
    "def mann_whitney_analysis(one_tokens, two_tokens):\n",
    "    \n",
    "    pvals=mann_whitney(one_tokens, two_tokens)\n",
    "    \n",
    "    # Mann-Whitney tells us the significance of a term's difference in two groups, but we also \n",
    "    # need the directionality of that difference (whether it's used more by group A or group B. \n",
    "    \n",
    "    # Let's use our difference-in-proportions function above to check the directionality.  \n",
    "    # [Note we could also measure directionality by checking whether the Mann-Whitney statistic\n",
    "    # is greater or less than the mean=len(one_chunks)*len(two_chunks)*0.5.]\n",
    "\n",
    "    differences=count_differences(one_tokens, two_tokens)\n",
    "    \n",
    "    one_terms={k : pvals[k] for k in pvals if differences[k] <= 0}\n",
    "    two_terms={k : pvals[k] for k in pvals if differences[k] > 0}\n",
    "    \n",
    "    sorted_pvals = sorted(one_terms.items(), key=operator.itemgetter(1))\n",
    "    print(\"More Republican:\\n\")\n",
    "    for k,v in sorted_pvals[:20]:\n",
    "        print(\"%s\\t%.15f\" % (k,v))\n",
    "\n",
    "    print(\"\\nMore Democrat:\\n\")\n",
    "    sorted_pvals = sorted(two_terms.items(), key=operator.itemgetter(1))\n",
    "    for k,v in sorted_pvals[:25]:\n",
    "        print(\"%s\\t%.15f\" % (k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mann_whitney_analysis(democrat_tokens, republican_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are the differences identified by Mann-Whitney similar to, and different from, those identified by $\\chi^2$?  What conclusions would you draw from the differences between these platforms?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log-odds ratio\n",
    "\n",
    "The log-odds ratio with an informative (and uninformative) Dirichlet prior (described in [Monroe et al. 2009, Fighting Words](http://languagelog.ldc.upenn.edu/myl/Monroe.pdf)) is a very common method for finding distinctive terms in two datasets (see [Jurafsky et al. 2014](https://firstmonday.org/ojs/index.php/fm/article/view/4944/3863) for an example article that uses it to make an empirical argument).  This method for finding distinguishing words combines a number of desirable properties:\n",
    "\n",
    "* it specifies an intuitive metric (the log-odds) for the ratio of two probabilities\n",
    "* it can incorporate prior information in the form of pseudocounts, which can either act as a smoothing factor (in the uninformative case) or incorporate real information about the expected frequency of words overall.\n",
    "* it accounts for variability of a frequency estimate by essentially converting the log-odds to a z-score.\n",
    "\n",
    "For the log-odds ratio with an uninformative Dirichlet prior, $\\hat\\zeta_w^{(i-j)}$ for word $w$ reflects the difference in usage between corpus $i$ and corpus $j$ and is given by the following equation:\n",
    "\n",
    "This value, $\\hat\\zeta_w^{(i-j)}$ for word $w$ reflecting the difference in usage between corpus $i$ and corpus $j$, is given by the following equation:\n",
    "\n",
    "$$\n",
    "\\hat\\zeta_w^{(i-j)}= {\\hat{d}_w^{(i-j)} \\over \\sqrt{\\sigma^2\\left(\\hat{d}_w^{(i-j)}\\right)}}\n",
    "$$\n",
    "\n",
    "Where: \n",
    "\n",
    "$$\n",
    "\\hat{d}_w^{(i-j)} = \\log \\left({y_w^i + \\alpha_w} \\over {n^i + \\alpha_0 - y_w^i - \\alpha_w}) \\right) -  \\log \\left({y_w^j + \\alpha_w} \\over {n^j + \\alpha_0 - y_w^j - \\alpha_w}) \\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma^2\\left(\\hat{d}_w^{(i-j)}\\right) \\approx {1 \\over {y_w^i + \\alpha_w}} + {1 \\over {y_w^j + \\alpha_w} }\n",
    "$$\n",
    "\n",
    "And:\n",
    "\n",
    "* $y_w^i = $ count of word $w$ in corpus $i$ (likewise for $j$)\n",
    "* $\\alpha_w$ = 0.01\n",
    "* $V$ = size of vocabulary (number of distinct word types)\n",
    "* $\\alpha_0 = V * \\alpha_w$\n",
    "* $n^i = $ number of words in corpus $i$ (likewise for $j$)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logodds_with_uninformative_prior(one_tokens, two_tokens, display=25):\n",
    "    \n",
    "    def get_counter_from_list(tokens):\n",
    "        counter=Counter()\n",
    "        for token in tokens:\n",
    "            counter[token]+=1\n",
    "        return counter\n",
    "\n",
    "\n",
    "    oneCounter=get_counter_from_list(one_tokens)\n",
    "    twoCounter=get_counter_from_list(two_tokens)\n",
    "    \n",
    "    vocab=dict(oneCounter) \n",
    "    vocab.update(dict(twoCounter))\n",
    "    oneSum=sum(oneCounter.values())\n",
    "    twoSum=sum(twoCounter.values())\n",
    "\n",
    "    ranks={}\n",
    "    alpha=0.01\n",
    "    alphaV=len(vocab)*alpha\n",
    "        \n",
    "    for word in vocab:\n",
    "        \n",
    "        log_odds_ratio=math.log( (oneCounter[word] + alpha) / (oneSum+alphaV-oneCounter[word]-alpha) ) - math.log( (twoCounter[word] + alpha) / (twoSum+alphaV-twoCounter[word]-alpha) )\n",
    "        variance=1./(oneCounter[word] + alpha) + 1./(twoCounter[word] + alpha)\n",
    "        \n",
    "        ranks[word]=log_odds_ratio/math.sqrt(variance)\n",
    "\n",
    "    sorted_x = sorted(ranks.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "    print(\"Most positive:\")\n",
    "    for k,v in sorted_x[:display]:\n",
    "        print(\"%.3f\\t%s\" % (v,k))\n",
    "    \n",
    "    print(\"\\nMost negative:\")\n",
    "    for k,v in reversed(sorted_x[-display:]):\n",
    "        print(\"%.3f\\t%s\" % (v,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logodds_with_uninformative_prior(republican_tokens, democrat_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore \n",
    "\n",
    "Explore these methods further by plugging your own texts into the process above. The texts should differ along some salient dimension that's of interest to you -- e.g., author, genre, topic, time period, etc.  ([Project Gutenberg](https://www.gutenberg.org) is one source for texts you could use here.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
